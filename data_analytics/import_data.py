import os
import pandas as pd
import json
from data_setup import DataSetup

class ImportData:
    def __init__(self):
        directory_path = "aggregated_data"  # Change to your directory path
        output_dir = "data_analytics/saved_data"  # Change to your desired output directory
        self.jar_samples, self.exe_samples = self.read_json_files_in_directory(directory_path, output_dir)
        self.jar = DataSetup(self.jar_samples, 'jar')
        self.exe = DataSetup(self.exe_samples, 'exe')


    def save_dataframes_to_disk(self, jar_samples, exe_samples, output_dir):
        # Create the output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Save DataFrames to CSV files
        if not jar_samples.empty:
            jar_samples.to_csv(os.path.join(output_dir, 'jar_samples.csv'), index=False)

        if not exe_samples.empty:
            exe_samples.to_csv(os.path.join(output_dir, 'exe_samples.csv'), index=False)

    def load_dataframes_from_disk(self, output_dir):
        jar_samples = pd.read_csv(os.path.join(output_dir, 'jar_samples.csv'))
        exe_samples = pd.read_csv(os.path.join(output_dir, 'exe_samples.csv'))
        
        return jar_samples, exe_samples

    def read_json_files_in_directory(self, directory_path, output_dir):
        # Check if saved DataFrames exist on disk
        if os.path.exists(os.path.join(output_dir, 'jar_samples.csv')) and os.path.exists(os.path.join(output_dir, 'exe_samples.csv')):
            print("Loading DataFrames from disk...")
            jar_samples, exe_samples = self.load_dataframes_from_disk(output_dir)
        else:
            # Initialize empty DataFrames for different file types
            jar_samples = pd.DataFrame()
            exe_samples = pd.DataFrame()

            # List all files in the directory
            for filename in os.listdir(directory_path):
                if filename.endswith(".json"):
                    file_path = os.path.join(directory_path, filename)

                    # Read the JSON file as a dictionary
                    try:
                        with open(file_path, 'r') as json_file:
                            data = json.load(json_file)

                        name = data.get('live', {}).get('application', {}).get('name', '')

                        if isinstance(name, str):
                            if name.endswith('.jar'):
                                # Flatten and normalize the nested data
                                flattened_data = pd.json_normalize(data)
                                jar_samples = pd.concat([jar_samples, flattened_data], ignore_index=True)
                            elif name.endswith('.exe') or name.endswith('.msi'):
                                # Flatten and normalize the nested data
                                flattened_data = pd.json_normalize(data)
                                exe_samples = pd.concat([exe_samples, flattened_data], ignore_index=True)
                    except Exception as e:
                        print(f"Error reading {filename}: {str(e)}")

            if jar_samples.empty and exe_samples.empty:
                print("No JSON files matching the criteria found in the directory.")
                return None, None

            # Save DataFrames to disk
            self.save_dataframes_to_disk(jar_samples, exe_samples, output_dir)

        return jar_samples, exe_samples