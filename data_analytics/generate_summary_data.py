from import_data import ImportData
dataset = ImportData()
import pandas as pd


def file_stats():
    # Read the CSV file into a DataFrame
    df = pd.read_csv('sample_list.csv')

    # Separate data into two DataFrames: malicious and nonmalicious
    malicious = df[df['detections'] >= 1]
    nonmalicious = df[df['detections'] == 0]

    # Create a DataFrame to store summary statistics
    summary_data = pd.DataFrame(columns=['Mean', 'Median', 'Min', 'Max'])

    # Calculate statistics for malicious and nonmalicious file sizes
    summary_data.loc['Malicious File Size'] = [
        round(malicious['size'].mean() / (1024 ** 2), 2),
        round(malicious['size'].median() / (1024 ** 2), 2),
        round(malicious['size'].min() / (1024 ** 2), 2),
        round(malicious['size'].max() / (1024 ** 2), 2)
    ]
    summary_data.loc['Nonmalicious File Size'] = [
        round(nonmalicious['size'].mean() / (1024 ** 2), 2),
        round(nonmalicious['size'].median() / (1024 ** 2), 2),
        round(nonmalicious['size'].min() / (1024 ** 2), 2),
        round(nonmalicious['size'].max() / (1024 ** 2), 2)
    ]

    # Calculate statistics for malicious and nonmalicious total submissions
    summary_data.loc['Malicious Submissions'] = [
        round(malicious['total_submissions'].mean(), 2),
        round(malicious['total_submissions'].median(), 2),
        round(malicious['total_submissions'].min(), 2),
        round(malicious['total_submissions'].max(), 2)
    ]
    summary_data.loc['Nonmalicious Submissions'] = [
        round(nonmalicious['total_submissions'].mean(), 2),
        round(nonmalicious['total_submissions'].median(), 2),
        round(nonmalicious['total_submissions'].min(), 2),
        round(nonmalicious['total_submissions'].max(), 2)
    ]

    # Calculate statistics for malicious and nonmalicious detections
    summary_data.loc['Malicious Detections'] = [
        round(malicious['detections'].mean(), 2),
        round(malicious['detections'].median(), 2),
        round(malicious['detections'].min(), 2),
        round(malicious['detections'].max(), 2)
    ]
    summary_data.loc['Nonmalicious Detections'] = [
        round(nonmalicious['detections'].mean(), 2),
        round(nonmalicious['detections'].median(), 2),
        round(nonmalicious['detections'].min(), 2),
        round(nonmalicious['detections'].max(), 2)
    ]
    # Save the summary statistics to a CSV file
    summary_data.to_csv('data_analytics/file_summary_statistics.csv', header=['Mean', 'Median', 'Min', 'Max'])

def year_submission_stats():

    # Read the CSV file into a DataFrame
    df = pd.read_csv('sample_list.csv')

    # Extract the year from the 'submission_date' column and create a new 'year' column
    df['year'] = pd.to_datetime(df['submission_date']).dt.year

    # Separate data into two DataFrames: malicious and nonmalicious
    malicious = df[df['detections'] >= 1]
    nonmalicious = df[df['detections'] == 0]

    # Group by 'year' and count the number of entries for malicious and nonmalicious submissions
    malicious_counts = malicious.groupby('year')['detections'].count()
    nonmalicious_counts = nonmalicious.groupby('year')['detections'].count()

    # Create a DataFrame for the summary
    summary_data = pd.DataFrame({'Malicious': malicious_counts, 'Nonmalicious': nonmalicious_counts})

    # Fill missing years with 0 counts
    years = range(df['year'].min(), df['year'].max() + 1)
    summary_data = summary_data.reindex(years, fill_value=0)

    # Save the summary statistics to a CSV file
    summary_data.to_csv('data_analytics/yearly_summary_statistics.csv')


# Usage example:
if __name__ == "__main__":


    # #dataset.jar.train_set.to_csv('data_analytics/training_set.csv')
    # filtered_df = dataset.exe.train_set[dataset.exe.train_set['VirusTotal.malicious'] == 1]
    # filtered_df2 = dataset.exe.train_set[dataset.exe.train_set['VirusTotal.malicious'] == 0]
    # print(f"shape: {filtered_df.shape}")
    # print(f"shape: {filtered_df2.shape}")

    # filtered_df5 = dataset.exe.test_set[dataset.exe.test_set['VirusTotal.malicious'] == 1]
    # filtered_df6 = dataset.exe.test_set[dataset.exe.test_set['VirusTotal.malicious'] == 0]
    # print(f"shape: {filtered_df5.shape}")
    # print(f"shape: {filtered_df6.shape}")

    # filtered_df3 = dataset.jar.train_set[dataset.jar.train_set['VirusTotal.malicious'] == 1]
    # filtered_df4 = dataset.jar.train_set[dataset.jar.train_set['VirusTotal.malicious'] == 0]
    # print(f"shape: {filtered_df3.shape}")
    # print(f"shape: {filtered_df4.shape}")

    # filtered_df7 = dataset.jar.test_set[dataset.jar.train_set['VirusTotal.malicious'] == 1]
    # filtered_df8 = dataset.jar.test_set[dataset.jar.train_set['VirusTotal.malicious'] == 0]
    # print(f"shape: {filtered_df7.shape}")
    # print(f"shape: {filtered_df8.shape}")


    file_stats()
    year_submission_stats()

    # Save the summary statistics to a CSV file
    summary_df.to_csv('data_analytics/file_summary_statistics.csv')


    dataset.jar.calculate_summary_statistics(dataset.jar.train_set,'data_analytics/jar_summary_stats.csv')
    dataset.exe.calculate_summary_statistics(dataset.exe.train_set,'data_analytics/exe_summary_stats.csv')

    dataset.jar.generate_correlation_matrix(dataset.jar.train_set)
    dataset.exe.generate_correlation_matrix(dataset.exe.train_set)

