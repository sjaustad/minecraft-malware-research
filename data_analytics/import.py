import os
import pandas as pd
import json
from data_setup import DataSetup

def save_dataframes_to_disk(jar_samples, exe_samples, output_dir):
    # Create the output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Save DataFrames to CSV files
    if not jar_samples.empty:
        jar_samples.to_csv(os.path.join(output_dir, 'jar_samples.csv'), index=False)

    if not exe_samples.empty:
        exe_samples.to_csv(os.path.join(output_dir, 'exe_samples.csv'), index=False)

def load_dataframes_from_disk(output_dir):
    jar_samples = pd.read_csv(os.path.join(output_dir, 'jar_samples.csv'))
    exe_samples = pd.read_csv(os.path.join(output_dir, 'exe_samples.csv'))
    
    return jar_samples, exe_samples

def read_json_files_in_directory(directory_path, output_dir):
    # Check if saved DataFrames exist on disk
    if os.path.exists(os.path.join(output_dir, 'jar_samples.csv')) and os.path.exists(os.path.join(output_dir, 'exe_samples.csv')):
        print("Loading DataFrames from disk...")
        jar_samples, exe_samples = load_dataframes_from_disk(output_dir)
    else:
        # Initialize empty DataFrames for different file types
        jar_samples = pd.DataFrame()
        exe_samples = pd.DataFrame()

        # List all files in the directory
        for filename in os.listdir(directory_path):
            if filename.endswith(".json"):
                file_path = os.path.join(directory_path, filename)

                # Read the JSON file as a dictionary
                try:
                    with open(file_path, 'r') as json_file:
                        data = json.load(json_file)

                    name = data.get('live', {}).get('application', {}).get('name', '')

                    if isinstance(name, str):
                        if name.endswith('.jar'):
                            # Flatten and normalize the nested data
                            flattened_data = pd.json_normalize(data)
                            jar_samples = pd.concat([jar_samples, flattened_data], ignore_index=True)
                        elif name.endswith('.exe') or name.endswith('.msi'):
                            # Flatten and normalize the nested data
                            flattened_data = pd.json_normalize(data)
                            exe_samples = pd.concat([exe_samples, flattened_data], ignore_index=True)
                except Exception as e:
                    print(f"Error reading {filename}: {str(e)}")

        if jar_samples.empty and exe_samples.empty:
            print("No JSON files matching the criteria found in the directory.")
            return None, None

        # Save DataFrames to disk
        save_dataframes_to_disk(jar_samples, exe_samples, output_dir)

    return jar_samples, exe_samples



# Usage example:
if __name__ == "__main__":
    directory_path = "aggregated_data"  # Change to your directory path
    output_dir = "data_analytics/saved_data"  # Change to your desired output directory
    jar_samples, exe_samples = read_json_files_in_directory(directory_path, output_dir)

    #jar_samples.to_csv('data_analytics/jar_out.csv')

    jar = DataSetup(jar_samples, 'jar')
    exe = DataSetup(exe_samples, 'exe')

    jar.train_set.to_csv('data_analytics/training_set.csv')

    jar.calculate_summary_statistics(jar.train_set,'data_analytics/jar_summary_stats.csv')
    exe.calculate_summary_statistics(jar.train_set,'data_analytics/exe_summary_stats.csv')

    jar.generate_correlation_matrix(jar.train_set)
    exe.generate_correlation_matrix(exe.train_set)